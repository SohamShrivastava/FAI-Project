ğŸ Reinforcement Learning Snake Game

A complete reinforcement-learning project implementing Random, SARSA, and Deep Q-Network (DQN) agents to play the classic Snake game.
Built using Python, PyTorch, and Pygame.

ğŸš€ Overview

This repository contains a modular RL framework for training different agents on a custom Snake environment.
It includes:

âœ” Custom Snake environment with Pygame

âœ” Three agent types: Random, SARSA, DQN

âœ” Replay memory + batch training for DQN

âœ” Neural network model with checkpoint saving

âœ” Clear code structure & extensible design

ğŸ“‚ Project Structure
â”œâ”€â”€ agents.py         
â”œâ”€â”€ environment.py   
â”œâ”€â”€ neural_net.py     
â”œâ”€â”€ run_experiment.py           
â””â”€â”€ README.md

ğŸ® Snake Environment (environment.py)
ğŸ“Œ State Representation (11 Features)

Each state is encoded as an 11-dimensional binary vector, providing compact but rich information:

Category	                            Features
Danger Awareness	                    1. Danger straight
                                      2. Danger right
                                      3. Danger left
                                      
Current Movement Direction	          4. Moving left
                                      5. Moving right
                                      6. Moving up
                                      7. Moving down
                                      
Food Location (Relative to Head)	    8. Food left
                                      9. Food right
                                      10. Food up
                                      11. Food down


ğŸ’€ Game Termination Conditions

The episode ends when any of the following occurs:

  ğŸ§± Snake hits the wall
  ğŸŒ€ Snake collides with its own body
  â³ Starvation


ğŸ§  Reinforcement Learning Agents (agent.py)

ğŸ² RandomAgent

A simple baseline agent that:
  1. Selects actions uniformly at random
  2. Provides a reference point for evaluating learning agents
     

ğŸ“˜ SARSA Agent (Tabular SARSA(0))

Implements a classical on-policy Temporal Difference method.

Key Features:
  1. Îµ-greedy exploration (decays with number of games)
  2. Tabular Q-learning structure


ğŸ¤– DQN Agent (Deep Q-Learning)
A neural networkâ€“based agent capable of learning advanced strategies.
